{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:38:23.327950Z","iopub.execute_input":"2026-01-31T22:38:23.328142Z","iopub.status.idle":"2026-01-31T22:38:24.464148Z","shell.execute_reply.started":"2026-01-31T22:38:23.328122Z","shell.execute_reply":"2026-01-31T22:38:24.463400Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:38:27.146685Z","iopub.execute_input":"2026-01-31T22:38:27.147031Z","iopub.status.idle":"2026-01-31T22:38:34.261144Z","shell.execute_reply.started":"2026-01-31T22:38:27.146994Z","shell.execute_reply":"2026-01-31T22:38:34.260505Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"batch_size= 64\nepochs= 30\nlearning_rate= 0.001\ndevice= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nseed= 42\n\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nprint(f\"using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:38:37.646240Z","iopub.execute_input":"2026-01-31T22:38:37.646672Z","iopub.status.idle":"2026-01-31T22:38:37.910611Z","shell.execute_reply.started":"2026-01-31T22:38:37.646645Z","shell.execute_reply":"2026-01-31T22:38:37.909991Z"}},"outputs":[{"name":"stdout","text":"using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train= pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest= pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nprint(train.head())\nprint(test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:38:40.945766Z","iopub.execute_input":"2026-01-31T22:38:40.946537Z","iopub.status.idle":"2026-01-31T22:38:44.521819Z","shell.execute_reply.started":"2026-01-31T22:38:40.946504Z","shell.execute_reply":"2026-01-31T22:38:44.521213Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]\n   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Datasetitself(Dataset):\n    def __init__(self, data, transform=None, is_test=False):\n        self.transform= transform\n        self.is_test= is_test\n\n        if self.is_test:\n            self.X= data.values.reshape((-1,28,28,1)).astype(np.uint8)\n            self.y= None\n        else:\n            self.X= data.iloc[:, 1:].values.reshape((-1,28,28,1)).astype(np.uint8)\n            self.y= torch.from_numpy(data.iloc[:,0].values).type(torch.LongTensor)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self,idx):\n        images= self.X[idx]\n\n        if self.transform:\n            images= self.transform(images)\n        if self.is_test:\n            return images\n        else:\n            return images, self.y[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:42:46.006829Z","iopub.execute_input":"2026-01-31T22:42:46.007384Z","iopub.status.idle":"2026-01-31T22:42:46.012971Z","shell.execute_reply.started":"2026-01-31T22:42:46.007356Z","shell.execute_reply":"2026-01-31T22:42:46.012209Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"print ('Loading dataset.....')\ntrain_df= pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_df= pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nprint ('Dataset loaded')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:43:10.182780Z","iopub.execute_input":"2026-01-31T22:43:10.183494Z","iopub.status.idle":"2026-01-31T22:43:13.057611Z","shell.execute_reply.started":"2026-01-31T22:43:10.183462Z","shell.execute_reply":"2026-01-31T22:43:13.056800Z"}},"outputs":[{"name":"stdout","text":"Loading dataset.....\nDataset loaded\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Data processing and augmentation","metadata":{}},{"cell_type":"code","source":"# train_val split\ntrain_data, val_data = train_test_split(train_df, test_size=0.1, random_state=seed)\n\ntrain_transform= transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(degrees= 10),\n    transforms.RandomAffine(degrees= 0, translate=(0.1, 0.1), scale= (0.9,1.1)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean= [0.5],std=[0.5])\n])\n\nval_transform= transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\ntrain_dataset= Datasetitself(train_data, transform= train_transform)\nval_dataset= Datasetitself(val_data, transform= val_transform)\ntest_dataset= Datasetitself(test_df, transform= val_transform, is_test=True)\n\ntrain_loader= DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\nval_loader= DataLoader(val_dataset, batch_size= batch_size, shuffle=False)\ntest_loader= DataLoader(test_dataset, batch_size= batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:43:15.210614Z","iopub.execute_input":"2026-01-31T22:43:15.211161Z","iopub.status.idle":"2026-01-31T22:43:15.456291Z","shell.execute_reply.started":"2026-01-31T22:43:15.211130Z","shell.execute_reply":"2026-01-31T22:43:15.455687Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# CNN Model Arch","metadata":{}},{"cell_type":"code","source":"class MNISTNet(nn.Module):\n    def __init__ (self):\n        super(MNISTNet, self).__init__()\n\n        #Block 1\n        self.conv1= nn.Sequential(\n            nn.Conv2d(1,32,kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32,32,kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout(0.25)\n        )\n\n         #Block 2\n        self.conv2= nn.Sequential(\n            nn.Conv2d(32,64,kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64,64,kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout(0.25)\n        )\n\n        #FC\n        self.fc= nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64*7*7, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x= self.conv1(x)\n        x= self.conv2(x)\n        x= self.fc(x)\n        return x\n\nmodel= MNISTNet().to(device)\noptimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\ncriterion = nn.CrossEntropyLoss()\nscheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:39:03.585322Z","iopub.execute_input":"2026-01-31T22:39:03.586101Z","iopub.status.idle":"2026-01-31T22:39:03.865479Z","shell.execute_reply.started":"2026-01-31T22:39:03.586068Z","shell.execute_reply":"2026-01-31T22:39:03.864862Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"print ('Started Training...')\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss= 0.0\n\n    for images, labels in train_loader:\n        images, labels= images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs= model(images)\n        loss= criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    #Val\n    model.eval()\n    total= 0\n    correct= 0\n    with torch.no_grad():\n        for images, labels in val_loader:    \n            images, labels = images.to(device), labels.to(device)\n            outputs= model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_acc= correct / total\n    scheduler.step(val_acc)\n\n    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(train_loader):.4f} | Val Acc: {val_acc:.4f}\")\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:43:20.200015Z","iopub.execute_input":"2026-01-31T22:43:20.200576Z","iopub.status.idle":"2026-01-31T22:52:49.009250Z","shell.execute_reply.started":"2026-01-31T22:43:20.200533Z","shell.execute_reply":"2026-01-31T22:52:49.008507Z"}},"outputs":[{"name":"stdout","text":"Started Training...\nEpoch 1/30 | Loss: 0.2349 | Val Acc: 0.9810\nEpoch 2/30 | Loss: 0.1095 | Val Acc: 0.9890\nEpoch 3/30 | Loss: 0.0915 | Val Acc: 0.9907\nEpoch 4/30 | Loss: 0.0818 | Val Acc: 0.9898\nEpoch 5/30 | Loss: 0.0737 | Val Acc: 0.9895\nEpoch 6/30 | Loss: 0.0791 | Val Acc: 0.9936\nEpoch 7/30 | Loss: 0.0754 | Val Acc: 0.9931\nEpoch 8/30 | Loss: 0.0694 | Val Acc: 0.9907\nEpoch 9/30 | Loss: 0.0690 | Val Acc: 0.9933\nEpoch 10/30 | Loss: 0.0663 | Val Acc: 0.9931\nEpoch 11/30 | Loss: 0.0568 | Val Acc: 0.9943\nEpoch 12/30 | Loss: 0.0522 | Val Acc: 0.9952\nEpoch 13/30 | Loss: 0.0496 | Val Acc: 0.9933\nEpoch 14/30 | Loss: 0.0488 | Val Acc: 0.9945\nEpoch 15/30 | Loss: 0.0507 | Val Acc: 0.9955\nEpoch 16/30 | Loss: 0.0482 | Val Acc: 0.9948\nEpoch 17/30 | Loss: 0.0497 | Val Acc: 0.9933\nEpoch 18/30 | Loss: 0.0497 | Val Acc: 0.9955\nEpoch 19/30 | Loss: 0.0517 | Val Acc: 0.9945\nEpoch 20/30 | Loss: 0.0476 | Val Acc: 0.9955\nEpoch 21/30 | Loss: 0.0452 | Val Acc: 0.9957\nEpoch 22/30 | Loss: 0.0452 | Val Acc: 0.9950\nEpoch 23/30 | Loss: 0.0404 | Val Acc: 0.9945\nEpoch 24/30 | Loss: 0.0439 | Val Acc: 0.9943\nEpoch 25/30 | Loss: 0.0467 | Val Acc: 0.9950\nEpoch 26/30 | Loss: 0.0420 | Val Acc: 0.9950\nEpoch 27/30 | Loss: 0.0414 | Val Acc: 0.9957\nEpoch 28/30 | Loss: 0.0402 | Val Acc: 0.9955\nEpoch 29/30 | Loss: 0.0399 | Val Acc: 0.9948\nEpoch 30/30 | Loss: 0.0379 | Val Acc: 0.9957\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"print(\"Generating predictions for test set...\")\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\nsubmission = pd.DataFrame({\n    \"ImageId\": range(1, len(predictions) + 1),\n    \"Label\": predictions\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T22:55:34.756998Z","iopub.execute_input":"2026-01-31T22:55:34.757947Z","iopub.status.idle":"2026-01-31T22:55:40.724027Z","shell.execute_reply.started":"2026-01-31T22:55:34.757911Z","shell.execute_reply":"2026-01-31T22:55:40.723331Z"}},"outputs":[{"name":"stdout","text":"Generating predictions for test set...\nsubmission.csv saved successfully!\n","output_type":"stream"}],"execution_count":22}]}